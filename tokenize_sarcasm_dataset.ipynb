{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sarcasm dataset from Kaggle and put it into the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./data/\"\n",
    "data_file = \"Sarcasm_Headlines_Dataset.json\"\n",
    "data_path = os.path.join(data_directory, data_file)\n",
    "\n",
    "data = [json.loads(x) for x in open(data_path).read().split(\"\\n\") if len(x)>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [entry.get('headline') for entry in data]\n",
    "labels = [entry.get('is_sarcastic') for entry in data]\n",
    "urls = [entry.get('article_link') for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former versace store clerk sues over secret 'black code' for minority shoppers\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of words in the word index :\n",
      "\n",
      "29657\n",
      "\n",
      "\n",
      "Words in order of commonality :\n",
      "\n",
      "['<OOV>', 'to', 'of', 'the', 'in', 'for', 'a', 'on', 'and', 'with', 'is', 'new', 'trump', 'man', 'from', 'at', 'about', 'you', 'this', 'by', 'after', 'up', 'out', 'be', 'how', 'as', 'it', 'that', 'not', 'are', 'your', 'his', 'what', 'he', 'all', 'just', 'who', 'has', 'will', 'more', 'one', 'into', 'report', 'year', 'why', 'have', 'area', 'over', 'donald', 'u', 'day', 'says', 's', 'can', 'first', 'woman', 'time', 'like', 'her', \"trump's\", 'old', 'no', 'get', 'off', 'an', 'life', 'people', 'obama', 'now', 'house', 'still', \"'\", 'women', 'make', 'was', 'than', 'white', 'back', 'my', 'i', 'clinton', 'down', 'if', '5', 'when', 'world', 'could', 'we', 'their', 'before', 'americans', 'way', 'do', 'family', 'most', 'gop', 'they', 'study', 'school', \"it's\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(\"\\nNumber of words in the word index :\\n\\n{}\\n\\n\".format(len(word_index)))\n",
    "print(\"Words in order of commonality :\\n\\n{}\\n\".format(list(word_index)[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(sequences, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_padded_seq(idx):\n",
    "    print(\"\\nOriginal sentence : \\n\\n    {}\\n\\n\".format(sentences[idx]))\n",
    "    print(\"Padded tokenized version : \\n\\n    {}\\n\\n\".format(padded[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original sentence : \n",
      "\n",
      "    airline passengers tackle man who rushes cockpit in bomb threat\n",
      "\n",
      "\n",
      "Padded tokenized version : \n",
      "\n",
      "    [2925 1680 4721   14   37 4275 6972    5 2095 1103    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "see_padded_seq(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Padded Sequence Matrix : \n",
      "\n",
      "(Examples, Padded Size)\n",
      "    (26709, 40)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nShape of Padded Sequence Matrix : \\n\\n{}\\n    {}\".format(\"(Examples, Padded Size)\",padded.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
